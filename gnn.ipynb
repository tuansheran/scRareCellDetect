{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\shera\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\torch\\utils\\_pytree.py:185: FutureWarning: optree is installed but the version is too old to support PyTorch Dynamo in C++ pytree. C++ pytree support is disabled. Please consider upgrading optree using `python3 -m pip install --upgrade 'optree>=0.13.0'`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from scipy.io import mmread\n",
    "from torch_geometric.data import Data\n",
    "from torch_geometric.nn import SAGEConv\n",
    "from sklearn.neighbors import kneighbors_graph\n",
    "from sklearn.cluster import DBSCAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<COOrdinate sparse matrix of dtype 'float64'\n",
      "\twith 86422438 stored elements and shape (34619, 27180)>\n",
      "  Coords\tValues\n",
      "  (30, 0)\t878.85046\n",
      "  (44, 0)\t2636.5513\n",
      "  (58, 0)\t878.85046\n",
      "  (74, 0)\t878.85046\n",
      "  (77, 0)\t878.85046\n",
      "  (109, 0)\t878.85046\n",
      "  (225, 0)\t3515.4019\n",
      "  (247, 0)\t878.85046\n",
      "  (272, 0)\t878.85046\n",
      "  (273, 0)\t1318.2756\n",
      "  (365, 0)\t878.85046\n",
      "  (366, 0)\t2636.5513\n",
      "  (421, 0)\t878.85046\n",
      "  (431, 0)\t1757.7009\n",
      "  (440, 0)\t878.85046\n",
      "  (442, 0)\t5273.1025\n",
      "  (499, 0)\t16698.158\n",
      "  (594, 0)\t878.85046\n",
      "  (649, 0)\t1757.7009\n",
      "  (688, 0)\t878.85046\n",
      "  (706, 0)\t878.85046\n",
      "  (831, 0)\t1757.7009\n",
      "  (835, 0)\t2636.5513\n",
      "  (867, 0)\t878.85046\n",
      "  (911, 0)\t2636.5513\n",
      "  :\t:\n",
      "  (32162, 27179)\t142.14685\n",
      "  (32202, 27179)\t88.841736\n",
      "  (32298, 27179)\t177.68347\n",
      "  (32423, 27179)\t59.227825\n",
      "  (32425, 27179)\t177.68347\n",
      "  (32564, 27179)\t88.841736\n",
      "  (33015, 27179)\t177.68347\n",
      "  (33454, 27179)\t177.68347\n",
      "  (33504, 27179)\t177.68347\n",
      "  (33538, 27179)\t177.68347\n",
      "  (33578, 27179)\t88.841736\n",
      "  (33636, 27179)\t177.68347\n",
      "  (33647, 27179)\t284.01257\n",
      "  (33727, 27179)\t88.841736\n",
      "  (33783, 27179)\t177.68347\n",
      "  (33801, 27179)\t177.68347\n",
      "  (33809, 27179)\t177.68347\n",
      "  (33814, 27179)\t177.68347\n",
      "  (33955, 27179)\t177.68347\n",
      "  (34155, 27179)\t59.227825\n",
      "  (34157, 27179)\t355.36694\n",
      "  (34188, 27179)\t1.9998602\n",
      "  (34279, 27179)\t177.68347\n",
      "  (34368, 27179)\t88.841736\n",
      "  (34393, 27179)\t1602.0801\n"
     ]
    }
   ],
   "source": [
    "rawData = mmread('scRNA.mtx')\n",
    "coo_matrix = rawData.tocoo()\n",
    "print(coo_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[  0.],\n",
      "        [  1.],\n",
      "        [  2.],\n",
      "        [  3.],\n",
      "        [  4.],\n",
      "        [  5.],\n",
      "        [  6.],\n",
      "        [  7.],\n",
      "        [  6.],\n",
      "        [  8.],\n",
      "        [  9.],\n",
      "        [ 20.],\n",
      "        [ 40.],\n",
      "        [ 50.],\n",
      "        [ 60.],\n",
      "        [ 70.],\n",
      "        [ 60.],\n",
      "        [100.],\n",
      "        [101.],\n",
      "        [102.],\n",
      "        [ 10.],\n",
      "        [ 99.]]) tensor([[120.],\n",
      "        [120.],\n",
      "        [110.],\n",
      "        [100.],\n",
      "        [ 90.],\n",
      "        [ 30.],\n",
      "        [ 89.],\n",
      "        [100.],\n",
      "        [ 90.],\n",
      "        [ 70.],\n",
      "        [ 78.],\n",
      "        [ 66.],\n",
      "        [120.],\n",
      "        [100.],\n",
      "        [110.]])\n",
      "tensor([[ 0,  0,  1,  1,  2,  2,  3,  3,  4,  4,  5,  5,  6,  6,  7,  7,  8,  8,\n",
      "          9,  9, 10, 10, 11, 11, 12, 12, 13, 13, 14, 14],\n",
      "        [12,  1, 12,  0, 14,  1, 13,  7,  8,  6, 11,  9,  8,  4, 13,  3,  4,  6,\n",
      "         11, 10,  9,  6,  9, 10,  0,  1,  7,  3,  2,  1]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\shera\\AppData\\Local\\Temp\\ipykernel_21936\\611621764.py:17: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\pytorch\\torch\\csrc\\utils\\tensor_new.cpp:257.)\n",
      "  edge_index = torch.tensor(adj_matrix.nonzero(), dtype=torch.long)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def split_train_test():\n",
    "    pass\n",
    "\n",
    "\n",
    "def build_cell_to_cell_graph(data):\n",
    "    \n",
    "    fakeDataSetCells = [0,1,2,3,4,5,6,7,6,8,9,20,40,50,60,70,60,100,101,102,10,99]\n",
    "    fakeDataSetExpressions = [120,120,110,100,90,30,89,100,90,70,78,66,120,100,110]\n",
    "\n",
    "    # cells = data.row\n",
    "    # expression = data.data\n",
    "\n",
    "    #float32 helps with memeory efficency\n",
    "    x = torch.tensor(fakeDataSetCells, dtype=torch.float32).unsqueeze(1) \n",
    "    y = torch.tensor(fakeDataSetExpressions, dtype=torch.float32).unsqueeze(1)\n",
    "    print(x,y)\n",
    "\n",
    "    #find top 5 smiliar cells using k-nearest neibgour \n",
    "    k = 2  # number of neighbors (adjust based on your needs)\n",
    "    adj_matrix = kneighbors_graph(y, n_neighbors=k, mode='connectivity', include_self=False)\n",
    "    edge_index = torch.tensor(adj_matrix.nonzero(), dtype=torch.long)\n",
    "    \n",
    "    print(edge_index)\n",
    "    # print(similarity_matrix)\n",
    "    data = Data(edge_index=edge_index, x=x)\n",
    "    return data\n",
    "\n",
    "data = build_cell_to_cell_graph(coo_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "num_nodes = 10\n",
    "\n",
    "class GraphSAGE(torch.nn.Module):\n",
    "    def __init__(self, in_channels, hidden_channels, out_channels):\n",
    "        super(GraphSAGE, self).__init__()\n",
    "        self.conv1 = SAGEConv(in_channels, hidden_channels, aggr=\"mean\")\n",
    "        self.conv2 = SAGEConv(hidden_channels, out_channels, aggr=\"mean\")\n",
    "    \n",
    "    def forward(self, x, edge_index):\n",
    "        x = F.relu(self.conv1(x, edge_index))\n",
    "        x = self.conv2(x, edge_index)\n",
    "        return x\n",
    "\n",
    "\n",
    "#loss function\n",
    "def contrastive_clustering_loss(embeddings, edge_index,margin=1.0):\n",
    "    src, dst = edge_index\n",
    "    pos_distances = (embeddings[src] - embeddings[dst]).pow(2).sum(dim=1)\n",
    "\n",
    "    neg_dst = torch.randint(0, embeddings.size(0), (edge_index.size(1),), device=embeddings.device)\n",
    "    neg_distances = (embeddings[src] - embeddings[neg_dst]).pow(2).sum(dim=1)\n",
    "    loss = F.relu(pos_distances - neg_distances + margin).mean()\n",
    "\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "data = data.to(device)\n",
    "model = GraphSAGE(in_channels=1, hidden_channels=16, out_channels=16).to(device)\n",
    "\n",
    "#implement optimizer\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 000, Loss: 354.1731\n",
      "Epoch: 020, Loss: 14.2802\n",
      "Epoch: 040, Loss: 25.3115\n",
      "Epoch: 060, Loss: 5.6164\n",
      "Epoch: 080, Loss: 0.9164\n",
      "Epoch: 100, Loss: 1.3584\n",
      "Epoch: 120, Loss: 1.3187\n",
      "Epoch: 140, Loss: 2.0002\n",
      "Epoch: 160, Loss: 1.8381\n",
      "Epoch: 180, Loss: 0.7326\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(200):\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "    embeddings = model(data.x, data.edge_index)\n",
    "    loss = contrastive_clustering_loss(embeddings, data.edge_index)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    if epoch % 20 == 0:\n",
    "        print(f'Epoch: {epoch:03d}, Loss: {loss:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#clustering\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
